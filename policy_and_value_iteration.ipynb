{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "policy_and_value_iteration.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/Yashwardhankaul/move37/blob/master/policy_and_value_iteration.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "rxvGulse3Gg0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Installing OpenAI gym"
      ]
    },
    {
      "metadata": {
        "id": "gWWm-YPK21wN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "705d1a00-52d7-4c49-924d-e77821dde319"
      },
      "cell_type": "code",
      "source": [
        "!pip install gym"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.6/dist-packages (0.10.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym) (1.11.0)\n",
            "Requirement already satisfied: pyglet>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym) (1.3.2)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym) (1.14.6)\n",
            "Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.6/dist-packages (from gym) (2.18.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet>=1.2.0->gym) (0.16.0)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (1.22)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (2018.8.24)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "I-rLOpsY3SAv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Importing Dependencies"
      ]
    },
    {
      "metadata": {
        "id": "ErjsXhJ13Wjv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from time import time\n",
        "import numpy as np\n",
        "import gym"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5-HM_Lz84K31",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Function for running the policy and calculating the reward"
      ]
    },
    {
      "metadata": {
        "id": "xQ-d6P7Q3cp3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def runPolicy(env,policy):\n",
        "  state = env.reset()\n",
        "  done = False\n",
        "  \n",
        "  totalReward = 0\n",
        "  while not done:\n",
        "    state, reward, done, _= env.step(policy[state])\n",
        "    totalReward += reward\n",
        "  return totalReward"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JKiPd1nz4xED",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Function for evaluating the policy"
      ]
    },
    {
      "metadata": {
        "id": "6KsAgfr-4G7q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def evaluatePolicy(env, policy, iterations):\n",
        "  totalRewards = 0\n",
        "  for i in range(iterations):\n",
        "    totalRewards += runPolicy(env, policy)\n",
        "  return totalRewards/iterations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4BR3dhpy44JH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Functions common for both value iteration and policy iteration"
      ]
    },
    {
      "metadata": {
        "id": "NKeswVFy42Sh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "eps = 1e-10\n",
        "\n",
        "def constructGreedyPolicy(env, values, gamma):\n",
        "  policy = np.zeros(env.env.nS)\n",
        "  for s in range(env.env.nS):\n",
        "    returns = [\n",
        "        sum(p * (r + gamma * values[ns])\n",
        "            for p, ns, r, _ in env.env.P[s][a])\n",
        "        for a in range(env.env.nA)\n",
        "    ]\n",
        "    policy[s] = np.argmax(returns)\n",
        "  \n",
        "  return policy\n",
        "\n",
        "def computeStateValues(env, gamma, policy = None, selectBest = False):\n",
        "  if policy is None and not selectBest:\n",
        "    raise 'When using computeStateValues either specify policy or pass selectBest=True!'\n",
        "  if policy is not None and selectBest:\n",
        "    raise 'You cannot use policy and selectBest at the same time'\n",
        "  \n",
        "  values = np.zeros(env.env.nS)\n",
        "  while True:\n",
        "    nextValues = values.copy()\n",
        "    for s in range(env.env.nS):\n",
        "      if policy is not None:\n",
        "        action = policy[s]\n",
        "        nextValues[s] = sum(p * (r + gamma * values[ns]) for p, ns, r, _ in env.env.P[s][action])\n",
        "      else:\n",
        "        nextValues[s] = max(\n",
        "            sum(p * (r + gamma * values[ns])\n",
        "                for p, ns, r, _ in env.env.P[s][a])\n",
        "            for a in range(env.env.nA)\n",
        "        )\n",
        "      \n",
        "    diff = np.fabs(nextValues - values).sum()\n",
        "    values = nextValues\n",
        "    if diff <= eps:\n",
        "      break\n",
        "  return values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o1Ys2Gec8PX-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Value Iteration"
      ]
    },
    {
      "metadata": {
        "id": "qdeWr4s58O1v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def valueIteration(env, gamma):\n",
        "  stateValues = computeStateValues(env, gamma, selectBest = True)\n",
        "  policy = constructGreedyPolicy(env, stateValues, gamma)\n",
        "  return policy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L5TY57jt8iwy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Policy Iteration"
      ]
    },
    {
      "metadata": {
        "id": "tOHzpVLK78-L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def randomPolicy(env):\n",
        "  return np.random.choice(env.env.nA, size=(env.env.nS))\n",
        "\n",
        "def policyIteration(env,gamma):\n",
        "  policy = randomPolicy(env)\n",
        "  while True:\n",
        "    stateValues = computeStateValues(env,gamma,policy)\n",
        "    nextPolicy = constructGreedyPolicy(env,stateValues,gamma)\n",
        "    if np.all(policy == nextPolicy):\n",
        "      break\n",
        "    policy = nextPolicy\n",
        "    \n",
        "  return policy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-c6qY-sN9pD3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Testing the Methods"
      ]
    },
    {
      "metadata": {
        "id": "7CvH-PtD9PKQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "2dcc5c92-3b78-4341-8bc7-76aeaad01f5d"
      },
      "cell_type": "code",
      "source": [
        "evaluateIterations = 1000\n",
        "\n",
        "def solveEnv(env, methods, envName):\n",
        "  print(f'Solving environment {envName}')\n",
        "  for method in methods:\n",
        "    name, f, gamma = method\n",
        "    tstart = time()\n",
        "    policy = f(env, gamma)\n",
        "    tend = time()\n",
        "    print(f'It took {tend - tstart} seconds to compute a policy using \"{name}\" with gamma={gamma}')\n",
        "    \n",
        "    score = evaluatePolicy(env, policy, evaluateIterations)\n",
        "    print(f'Policy average reward is {score}')\n",
        "  \n",
        "  \n",
        "methods = [\n",
        "  ('Value Iteration', valueIteration, 0.9),\n",
        "  ('Policy Iteration', policyIteration, 0.9),\n",
        "  ('Value Iteration', valueIteration, 0.98),\n",
        "  ('Policy Iteration', policyIteration, 0.98),\n",
        "  ('Value Iteration', valueIteration, 1),\n",
        "  ('Policy Iteration', policyIteration, 1),\n",
        "]\n",
        "\n",
        "frozenLake4 = gym.make('FrozenLake-v0')\n",
        "solveEnv(frozenLake4, methods, 'Frozen Lake 4x4')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Solving environment Frozen Lake 4x4\n",
            "It took 0.03473520278930664 seconds to compute a policy using \"Value Iteration\" with gamma=0.9\n",
            "Policy average reward is 0.734\n",
            "It took 0.05277681350708008 seconds to compute a policy using \"Policy Iteration\" with gamma=0.9\n",
            "Policy average reward is 0.75\n",
            "It took 0.09992027282714844 seconds to compute a policy using \"Value Iteration\" with gamma=0.98\n",
            "Policy average reward is 0.724\n",
            "It took 0.12077093124389648 seconds to compute a policy using \"Policy Iteration\" with gamma=0.98\n",
            "Policy average reward is 0.715\n",
            "It took 0.1971590518951416 seconds to compute a policy using \"Value Iteration\" with gamma=1\n",
            "Policy average reward is 0.715\n",
            "It took 0.09698224067687988 seconds to compute a policy using \"Policy Iteration\" with gamma=1\n",
            "Policy average reward is 0.751\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iBZuBG5Q_b3n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "4e4b6bf8-6586-419d-aaf4-990818083c75"
      },
      "cell_type": "code",
      "source": [
        "frozenLake8 = gym.make('FrozenLake8x8-v0')\n",
        "solveEnv(frozenLake8, methods,'Frozen Lake 8x8')"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Solving environment Frozen Lake 8x8\n",
            "It took 0.12558817863464355 seconds to compute a policy using \"Value Iteration\" with gamma=0.9\n",
            "Policy average reward is 0.739\n",
            "It took 0.1747450828552246 seconds to compute a policy using \"Policy Iteration\" with gamma=0.9\n",
            "Policy average reward is 0.75\n",
            "It took 0.3746812343597412 seconds to compute a policy using \"Value Iteration\" with gamma=0.98\n",
            "Policy average reward is 0.86\n",
            "It took 0.5252554416656494 seconds to compute a policy using \"Policy Iteration\" with gamma=0.98\n",
            "Policy average reward is 0.836\n",
            "It took 1.178382396697998 seconds to compute a policy using \"Value Iteration\" with gamma=1\n",
            "Policy average reward is 0.9\n",
            "It took 3.532578706741333 seconds to compute a policy using \"Policy Iteration\" with gamma=1\n",
            "Policy average reward is 0.88\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}