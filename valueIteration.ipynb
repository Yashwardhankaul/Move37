{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "valueIteration.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/Yashwardhankaul/move37/blob/master/valueIteration.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "i3JSaSDsaEbl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "8b669273-7098-443f-a039-13d556399210"
      },
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "import time \n",
        "!pip install gym"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gym\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/50/ed4a03d2be47ffd043be2ee514f329ce45d98a30fe2d1b9c61dea5a9d861/gym-0.10.5.tar.gz (1.5MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.5MB 6.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym) (1.14.5)\n",
            "Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.6/dist-packages (from gym) (2.18.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym) (1.11.0)\n",
            "Collecting pyglet>=1.2.0 (from gym)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/fc/dad5eaaab68f0c21e2f906a94ddb98175662cc5a654eee404d59554ce0fa/pyglet-1.3.2-py2.py3-none-any.whl (1.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.0MB 14.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (1.22)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (2.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (2018.8.24)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (3.0.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet>=1.2.0->gym) (0.16.0)\n",
            "Building wheels for collected packages: gym\n",
            "  Running setup.py bdist_wheel for gym ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/cb/14/71/f4ab006b1e6ff75c2b54985c2f98d0644fffe9c1dddc670925\n",
            "Successfully built gym\n",
            "Installing collected packages: pyglet, gym\n",
            "Successfully installed gym-0.10.5 pyglet-1.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ig3Oodg8dIrM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import gym"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3sfR8YjPdT1g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def execute(env, policy, episodeLength=100, render=False):\n",
        "  totalReward = 0\n",
        "  start = env.reset()\n",
        "  for t in range(episodeLength):\n",
        "    if render:\n",
        "      env.render()\n",
        "    action = policy[start]\n",
        "    start, reward, done, _= env.step(action)\n",
        "    totalReward += reward\n",
        "    if done:\n",
        "      break\n",
        "  return totalReward"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3glMqaNZeUl4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def evaluatePolicy(env, policy, n_episodes=100):\n",
        "  totalReward = 0.0\n",
        "  for _ in range(n_episodes):\n",
        "    totalReward += execute(env, policy)\n",
        "  return totalReward/ n_episodes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sHeq-E50e6DI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def gen_random_policy():\n",
        "  return numpy.random.choice(4, size=((16)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CBm3KKQYfKvI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ba6dcafc-ec26-4982-ba41-5d08e584a4fd"
      },
      "cell_type": "code",
      "source": [
        "env = gym.make('FrozenLake-v0')\n",
        "n_policies = 1000\n",
        "startTime = time.time()\n",
        "policy_set = [gen_random_policy() for _ in range(n_policies)]\n",
        "policy_score= [evaluatePolicy(env, p) for p in policy_set]\n",
        "endTime = time.time()\n",
        "print(\"Best Score = %0.2f. Time taken = %4.4f seconds\"%(numpy.max(policy_score),endTime-startTime))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Score = 0.70. Time taken = 12.2057 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6xT73NQ7ix5s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now using Value Iteration"
      ]
    },
    {
      "metadata": {
        "id": "iSnyXJpHgNiL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def execute(env,policy,gamma=1.0,render=False):\n",
        "  start=env.reset()\n",
        "  totalReward = 0\n",
        "  stepIndex = 0\n",
        "  while True:\n",
        "    if render:\n",
        "      env.render()\n",
        "    start,reward,done,_=env.step(int(policy[start]))\n",
        "    totalReward += (gamma**stepIndex*reward)\n",
        "    stepIndex += 1\n",
        "    if done:\n",
        "      break\n",
        "    return totalReward"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8soWIVpPj1vB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def evaluatePolicy(env, policy, gamma=1.0, n=100):\n",
        "  scores=[execute(env,policy,gamma=gamma,render=False) for _ in range(n)]\n",
        "  return numpy.mean(scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SJIrwRmCkWZ_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def calculatePolicy(v, gamma = 1.0):\n",
        "  policy = numpy.zeros(env.env.nS)\n",
        "  for s in range(env.env.nS):\n",
        "    q_sa = numpy.zeros(env.action_space.n)\n",
        "    for a in range(env.action_space.n):\n",
        "      for next_sr in env.env.P[s][a]:\n",
        "        p,s_,r,_ = next_sr\n",
        "        q_sa[a] += (p * (r + gamma * v[s_]))\n",
        "    policy[s] = numpy.argmax(q_sa)\n",
        "  return policy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CZVinsdlmAKW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def valueIteration(env, gamma = 1.0):\n",
        "  value = numpy.zeros(env.env.nS)\n",
        "  max_iterations=10000\n",
        "  eps = 1e-20\n",
        "  for i in range(max_iterations):\n",
        "    prev_v = numpy.copy(value)\n",
        "    for s in range(env.env.nS):\n",
        "      q_sa = [sum([p*(r + prev_v[s_]) for p,s_,r,_ in env.env.P[s][a]]) for a in range(env.env.nA)]\n",
        "      value[s] = max(q_sa)\n",
        "    if (numpy.sum(numpy.fabs(prev_v - value)) <= eps):\n",
        "      print(\"Value-iteration converged at # %d\"%(i + 1))\n",
        "      break\n",
        "  return value"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jUgxZwm7nd7D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "a99a936b-c4d4-4f0a-eff5-acfe24bdb470"
      },
      "cell_type": "code",
      "source": [
        "gamma = 1.0\n",
        "env= gym.make(\"FrozenLake-v0\")\n",
        "optimalValue = valueIteration(env,gamma)\n",
        "startTime = time.time()\n",
        "policy = calculatePolicy(optimalValue, gamma)\n",
        "policy_score = evaluatePolicy(env,policy,gamma,n=1000)\n",
        "endTime= time.time()\n",
        "print(policy_score)\n",
        "print(\"Best score = %0.2f. Time taken = %4.4f seconds\"%(numpy.mean(policy_score),endTime-startTime))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Value-iteration converged at # 1373\n",
            "0.0\n",
            "Best score = 0.00. Time taken = 0.0219 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "l6VGD3Z9oTQM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}